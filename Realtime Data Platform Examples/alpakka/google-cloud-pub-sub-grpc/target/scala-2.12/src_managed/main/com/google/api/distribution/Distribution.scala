// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package com.google.api.distribution

/** Distribution contains summary statistics for a population of values and,
  * optionally, a histogram representing the distribution of those values across
  * a specified set of histogram buckets.
  *
  * The summary statistics are the count, mean, sum of the squared deviation from
  * the mean, the minimum, and the maximum of the set of population of values.
  *
  * The histogram is based on a sequence of buckets and gives a count of values
  * that fall into each bucket.  The boundaries of the buckets are given either
  * explicitly or by specifying parameters for a method of computing them
  * (buckets of fixed width or buckets of exponentially increasing width).
  *
  * Although it is not forbidden, it is generally a bad idea to include
  * non-finite values (infinities or NaNs) in the population of values, as this
  * will render the `mean` and `sum_of_squared_deviation` fields meaningless.
  *
  * @param count
  *   The number of values in the population. Must be non-negative.
  * @param mean
  *   The arithmetic mean of the values in the population. If `count` is zero
  *   then this field must be zero.
  * @param sumOfSquaredDeviation
  *   The sum of squared deviations from the mean of the values in the
  *   population.  For values x_i this is:
  *  
  *       Sum[i=1..n]((x_i - mean)^2)
  *  
  *   Knuth, "The Art of Computer Programming", Vol. 2, page 323, 3rd edition
  *   describes Welford's method for accumulating this sum in one pass.
  *  
  *   If `count` is zero then this field must be zero.
  * @param range
  *   If specified, contains the range of the population values. The field
  *   must not be present if the `count` is zero.
  * @param bucketOptions
  *   Defines the histogram bucket boundaries.
  * @param bucketCounts
  *   If `bucket_options` is given, then the sum of the values in `bucket_counts`
  *   must equal the value in `count`.  If `bucket_options` is not given, no
  *   `bucket_counts` fields may be given.
  *  
  *   Bucket counts are given in order under the numbering scheme described
  *   above (the underflow bucket has number 0; the finite buckets, if any,
  *   have numbers 1 through N-2; the overflow bucket has number N-1).
  *  
  *   The size of `bucket_counts` must be no greater than N as defined in
  *   `bucket_options`.
  *  
  *   Any suffix of trailing zero bucket_count fields may be omitted.
  */
@SerialVersionUID(0L)
final case class Distribution(
    count: _root_.scala.Long = 0L,
    mean: _root_.scala.Double = 0.0,
    sumOfSquaredDeviation: _root_.scala.Double = 0.0,
    range: _root_.scala.Option[com.google.api.distribution.Distribution.Range] = None,
    bucketOptions: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions] = None,
    bucketCounts: _root_.scala.collection.Seq[_root_.scala.Long] = _root_.scala.collection.Seq.empty
    ) extends scalapb.GeneratedMessage with scalapb.Message[Distribution] with scalapb.lenses.Updatable[Distribution] {
    private[this] def bucketCountsSerializedSize = {
      if (__bucketCountsSerializedSizeField == 0) __bucketCountsSerializedSizeField = {
        var __s: _root_.scala.Int = 0
        bucketCounts.foreach(__i => __s += _root_.com.google.protobuf.CodedOutputStream.computeInt64SizeNoTag(__i))
        __s
      }
      __bucketCountsSerializedSizeField
    }
    @transient private[this] var __bucketCountsSerializedSizeField: _root_.scala.Int = 0
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = count
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
        }
      };
      
      {
        val __value = mean
        if (__value != 0.0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(2, __value)
        }
      };
      
      {
        val __value = sumOfSquaredDeviation
        if (__value != 0.0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(3, __value)
        }
      };
      if (range.isDefined) {
        val __value = range.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (bucketOptions.isDefined) {
        val __value = bucketOptions.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if(bucketCounts.nonEmpty) {
        val __localsize = bucketCountsSerializedSize
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__localsize) + __localsize
      }
      __size
    }
    final override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = count
        if (__v != 0L) {
          _output__.writeInt64(1, __v)
        }
      };
      {
        val __v = mean
        if (__v != 0.0) {
          _output__.writeDouble(2, __v)
        }
      };
      {
        val __v = sumOfSquaredDeviation
        if (__v != 0.0) {
          _output__.writeDouble(3, __v)
        }
      };
      range.foreach { __v =>
        val __m = __v
        _output__.writeTag(4, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      bucketOptions.foreach { __v =>
        val __m = __v
        _output__.writeTag(6, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      if (bucketCounts.nonEmpty) {
        _output__.writeTag(7, 2)
        _output__.writeUInt32NoTag(bucketCountsSerializedSize)
        bucketCounts.foreach(_output__.writeInt64NoTag)
      };
    }
    def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.google.api.distribution.Distribution = {
      var __count = this.count
      var __mean = this.mean
      var __sumOfSquaredDeviation = this.sumOfSquaredDeviation
      var __range = this.range
      var __bucketOptions = this.bucketOptions
      val __bucketCounts = (_root_.scala.collection.immutable.Vector.newBuilder[_root_.scala.Long] ++= this.bucketCounts)
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __count = _input__.readInt64()
          case 17 =>
            __mean = _input__.readDouble()
          case 25 =>
            __sumOfSquaredDeviation = _input__.readDouble()
          case 34 =>
            __range = Option(_root_.scalapb.LiteParser.readMessage(_input__, __range.getOrElse(com.google.api.distribution.Distribution.Range.defaultInstance)))
          case 50 =>
            __bucketOptions = Option(_root_.scalapb.LiteParser.readMessage(_input__, __bucketOptions.getOrElse(com.google.api.distribution.Distribution.BucketOptions.defaultInstance)))
          case 56 =>
            __bucketCounts += _input__.readInt64()
          case 58 => {
            val length = _input__.readRawVarint32()
            val oldLimit = _input__.pushLimit(length)
            while (_input__.getBytesUntilLimit > 0) {
              __bucketCounts += _input__.readInt64
            }
            _input__.popLimit(oldLimit)
          }
          case tag => _input__.skipField(tag)
        }
      }
      com.google.api.distribution.Distribution(
          count = __count,
          mean = __mean,
          sumOfSquaredDeviation = __sumOfSquaredDeviation,
          range = __range,
          bucketOptions = __bucketOptions,
          bucketCounts = __bucketCounts.result()
      )
    }
    def withCount(__v: _root_.scala.Long): Distribution = copy(count = __v)
    def withMean(__v: _root_.scala.Double): Distribution = copy(mean = __v)
    def withSumOfSquaredDeviation(__v: _root_.scala.Double): Distribution = copy(sumOfSquaredDeviation = __v)
    def getRange: com.google.api.distribution.Distribution.Range = range.getOrElse(com.google.api.distribution.Distribution.Range.defaultInstance)
    def clearRange: Distribution = copy(range = None)
    def withRange(__v: com.google.api.distribution.Distribution.Range): Distribution = copy(range = Option(__v))
    def getBucketOptions: com.google.api.distribution.Distribution.BucketOptions = bucketOptions.getOrElse(com.google.api.distribution.Distribution.BucketOptions.defaultInstance)
    def clearBucketOptions: Distribution = copy(bucketOptions = None)
    def withBucketOptions(__v: com.google.api.distribution.Distribution.BucketOptions): Distribution = copy(bucketOptions = Option(__v))
    def clearBucketCounts = copy(bucketCounts = _root_.scala.collection.Seq.empty)
    def addBucketCounts(__vs: _root_.scala.Long*): Distribution = addAllBucketCounts(__vs)
    def addAllBucketCounts(__vs: TraversableOnce[_root_.scala.Long]): Distribution = copy(bucketCounts = bucketCounts ++ __vs)
    def withBucketCounts(__v: _root_.scala.collection.Seq[_root_.scala.Long]): Distribution = copy(bucketCounts = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = count
          if (__t != 0L) __t else null
        }
        case 2 => {
          val __t = mean
          if (__t != 0.0) __t else null
        }
        case 3 => {
          val __t = sumOfSquaredDeviation
          if (__t != 0.0) __t else null
        }
        case 4 => range.orNull
        case 6 => bucketOptions.orNull
        case 7 => bucketCounts
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PLong(count)
        case 2 => _root_.scalapb.descriptors.PDouble(mean)
        case 3 => _root_.scalapb.descriptors.PDouble(sumOfSquaredDeviation)
        case 4 => range.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 6 => bucketOptions.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 7 => _root_.scalapb.descriptors.PRepeated(bucketCounts.map(_root_.scalapb.descriptors.PLong)(_root_.scala.collection.breakOut))
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = com.google.api.distribution.Distribution
}

object Distribution extends scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution] = this
  def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, _root_.scala.Any]): com.google.api.distribution.Distribution = {
    _root_.scala.Predef.require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
    val __fields = javaDescriptor.getFields
    com.google.api.distribution.Distribution(
      __fieldsMap.getOrElse(__fields.get(0), 0L).asInstanceOf[_root_.scala.Long],
      __fieldsMap.getOrElse(__fields.get(1), 0.0).asInstanceOf[_root_.scala.Double],
      __fieldsMap.getOrElse(__fields.get(2), 0.0).asInstanceOf[_root_.scala.Double],
      __fieldsMap.get(__fields.get(3)).asInstanceOf[_root_.scala.Option[com.google.api.distribution.Distribution.Range]],
      __fieldsMap.get(__fields.get(4)).asInstanceOf[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions]],
      __fieldsMap.getOrElse(__fields.get(5), Nil).asInstanceOf[_root_.scala.collection.Seq[_root_.scala.Long]]
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[com.google.api.distribution.Distribution] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      com.google.api.distribution.Distribution(
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Double]).getOrElse(0.0),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Double]).getOrElse(0.0),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).flatMap(_.as[_root_.scala.Option[com.google.api.distribution.Distribution.Range]]),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).flatMap(_.as[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions]]),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scala.collection.Seq[_root_.scala.Long]]).getOrElse(_root_.scala.collection.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = DistributionProto.javaDescriptor.getMessageTypes.get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = DistributionProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 4 => __out = com.google.api.distribution.Distribution.Range
      case 6 => __out = com.google.api.distribution.Distribution.BucketOptions
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq[_root_.scalapb.GeneratedMessageCompanion[_]](
    _root_.com.google.api.distribution.Distribution.Range,
    _root_.com.google.api.distribution.Distribution.BucketOptions
  )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = com.google.api.distribution.Distribution(
  )
  /** The range of the population values.
    *
    * @param min
    *   The minimum of the population values.
    * @param max
    *   The maximum of the population values.
    */
  @SerialVersionUID(0L)
  final case class Range(
      min: _root_.scala.Double = 0.0,
      max: _root_.scala.Double = 0.0
      ) extends scalapb.GeneratedMessage with scalapb.Message[Range] with scalapb.lenses.Updatable[Range] {
      @transient
      private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
      private[this] def __computeSerializedValue(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = min
          if (__value != 0.0) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(1, __value)
          }
        };
        
        {
          val __value = max
          if (__value != 0.0) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(2, __value)
          }
        };
        __size
      }
      final override def serializedSize: _root_.scala.Int = {
        var read = __serializedSizeCachedValue
        if (read == 0) {
          read = __computeSerializedValue()
          __serializedSizeCachedValue = read
        }
        read
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = min
          if (__v != 0.0) {
            _output__.writeDouble(1, __v)
          }
        };
        {
          val __v = max
          if (__v != 0.0) {
            _output__.writeDouble(2, __v)
          }
        };
      }
      def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.google.api.distribution.Distribution.Range = {
        var __min = this.min
        var __max = this.max
        var _done__ = false
        while (!_done__) {
          val _tag__ = _input__.readTag()
          _tag__ match {
            case 0 => _done__ = true
            case 9 =>
              __min = _input__.readDouble()
            case 17 =>
              __max = _input__.readDouble()
            case tag => _input__.skipField(tag)
          }
        }
        com.google.api.distribution.Distribution.Range(
            min = __min,
            max = __max
        )
      }
      def withMin(__v: _root_.scala.Double): Range = copy(min = __v)
      def withMax(__v: _root_.scala.Double): Range = copy(max = __v)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = min
            if (__t != 0.0) __t else null
          }
          case 2 => {
            val __t = max
            if (__t != 0.0) __t else null
          }
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PDouble(min)
          case 2 => _root_.scalapb.descriptors.PDouble(max)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion = com.google.api.distribution.Distribution.Range
  }
  
  object Range extends scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.Range] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.Range] = this
    def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, _root_.scala.Any]): com.google.api.distribution.Distribution.Range = {
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
      val __fields = javaDescriptor.getFields
      com.google.api.distribution.Distribution.Range(
        __fieldsMap.getOrElse(__fields.get(0), 0.0).asInstanceOf[_root_.scala.Double],
        __fieldsMap.getOrElse(__fields.get(1), 0.0).asInstanceOf[_root_.scala.Double]
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[com.google.api.distribution.Distribution.Range] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
        com.google.api.distribution.Distribution.Range(
          __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Double]).getOrElse(0.0),
          __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Double]).getOrElse(0.0)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = com.google.api.distribution.Distribution.javaDescriptor.getNestedTypes.get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = com.google.api.distribution.Distribution.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = com.google.api.distribution.Distribution.Range(
    )
    implicit class RangeLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.Range]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.google.api.distribution.Distribution.Range](_l) {
      def min: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.min)((c_, f_) => c_.copy(min = f_))
      def max: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.max)((c_, f_) => c_.copy(max = f_))
    }
    final val MIN_FIELD_NUMBER = 1
    final val MAX_FIELD_NUMBER = 2
    def of(
      min: _root_.scala.Double,
      max: _root_.scala.Double
    ): _root_.com.google.api.distribution.Distribution.Range = _root_.com.google.api.distribution.Distribution.Range(
      min,
      max
    )
  }
  
  /** A Distribution may optionally contain a histogram of the values in the
    * population.  The histogram is given in `bucket_counts` as counts of values
    * that fall into one of a sequence of non-overlapping buckets.  The sequence
    * of buckets is described by `bucket_options`.
    *
    * A bucket specifies an inclusive lower bound and exclusive upper bound for
    * the values that are counted for that bucket.  The upper bound of a bucket
    * is strictly greater than the lower bound.
    *
    * The sequence of N buckets for a Distribution consists of an underflow
    * bucket (number 0), zero or more finite buckets (number 1 through N - 2) and
    * an overflow bucket (number N - 1).  The buckets are contiguous:  the lower
    * bound of bucket i (i &gt; 0) is the same as the upper bound of bucket i - 1.
    * The buckets span the whole range of finite values: lower bound of the
    * underflow bucket is -infinity and the upper bound of the overflow bucket is
    * +infinity.  The finite buckets are so-called because both bounds are
    * finite.
    *
    * `BucketOptions` describes bucket boundaries in one of three ways.  Two
    * describe the boundaries by giving parameters for a formula to generate
    * boundaries and one gives the bucket boundaries explicitly.
    *
    * If `bucket_boundaries` is not given, then no `bucket_counts` may be given.
    */
  @SerialVersionUID(0L)
  final case class BucketOptions(
      options: com.google.api.distribution.Distribution.BucketOptions.Options = com.google.api.distribution.Distribution.BucketOptions.Options.Empty
      ) extends scalapb.GeneratedMessage with scalapb.Message[BucketOptions] with scalapb.lenses.Updatable[BucketOptions] {
      @transient
      private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
      private[this] def __computeSerializedValue(): _root_.scala.Int = {
        var __size = 0
        if (options.linearBuckets.isDefined) {
          val __value = options.linearBuckets.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        if (options.exponentialBuckets.isDefined) {
          val __value = options.exponentialBuckets.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        if (options.explicitBuckets.isDefined) {
          val __value = options.explicitBuckets.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        __size
      }
      final override def serializedSize: _root_.scala.Int = {
        var read = __serializedSizeCachedValue
        if (read == 0) {
          read = __computeSerializedValue()
          __serializedSizeCachedValue = read
        }
        read
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        options.linearBuckets.foreach { __v =>
          val __m = __v
          _output__.writeTag(1, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        options.exponentialBuckets.foreach { __v =>
          val __m = __v
          _output__.writeTag(2, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        options.explicitBuckets.foreach { __v =>
          val __m = __v
          _output__.writeTag(3, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
      }
      def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.google.api.distribution.Distribution.BucketOptions = {
        var __options = this.options
        var _done__ = false
        while (!_done__) {
          val _tag__ = _input__.readTag()
          _tag__ match {
            case 0 => _done__ = true
            case 10 =>
              __options = com.google.api.distribution.Distribution.BucketOptions.Options.LinearBuckets(_root_.scalapb.LiteParser.readMessage(_input__, options.linearBuckets.getOrElse(com.google.api.distribution.Distribution.BucketOptions.Linear.defaultInstance)))
            case 18 =>
              __options = com.google.api.distribution.Distribution.BucketOptions.Options.ExponentialBuckets(_root_.scalapb.LiteParser.readMessage(_input__, options.exponentialBuckets.getOrElse(com.google.api.distribution.Distribution.BucketOptions.Exponential.defaultInstance)))
            case 26 =>
              __options = com.google.api.distribution.Distribution.BucketOptions.Options.ExplicitBuckets(_root_.scalapb.LiteParser.readMessage(_input__, options.explicitBuckets.getOrElse(com.google.api.distribution.Distribution.BucketOptions.Explicit.defaultInstance)))
            case tag => _input__.skipField(tag)
          }
        }
        com.google.api.distribution.Distribution.BucketOptions(
            options = __options
        )
      }
      def getLinearBuckets: com.google.api.distribution.Distribution.BucketOptions.Linear = options.linearBuckets.getOrElse(com.google.api.distribution.Distribution.BucketOptions.Linear.defaultInstance)
      def withLinearBuckets(__v: com.google.api.distribution.Distribution.BucketOptions.Linear): BucketOptions = copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.LinearBuckets(__v))
      def getExponentialBuckets: com.google.api.distribution.Distribution.BucketOptions.Exponential = options.exponentialBuckets.getOrElse(com.google.api.distribution.Distribution.BucketOptions.Exponential.defaultInstance)
      def withExponentialBuckets(__v: com.google.api.distribution.Distribution.BucketOptions.Exponential): BucketOptions = copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.ExponentialBuckets(__v))
      def getExplicitBuckets: com.google.api.distribution.Distribution.BucketOptions.Explicit = options.explicitBuckets.getOrElse(com.google.api.distribution.Distribution.BucketOptions.Explicit.defaultInstance)
      def withExplicitBuckets(__v: com.google.api.distribution.Distribution.BucketOptions.Explicit): BucketOptions = copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.ExplicitBuckets(__v))
      def clearOptions: BucketOptions = copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.Empty)
      def withOptions(__v: com.google.api.distribution.Distribution.BucketOptions.Options): BucketOptions = copy(options = __v)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => options.linearBuckets.orNull
          case 2 => options.exponentialBuckets.orNull
          case 3 => options.explicitBuckets.orNull
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => options.linearBuckets.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 2 => options.exponentialBuckets.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 3 => options.explicitBuckets.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion = com.google.api.distribution.Distribution.BucketOptions
  }
  
  object BucketOptions extends scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions] = this
    def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, _root_.scala.Any]): com.google.api.distribution.Distribution.BucketOptions = {
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
      val __fields = javaDescriptor.getFields
      com.google.api.distribution.Distribution.BucketOptions(
        options = __fieldsMap.get(__fields.get(0)).asInstanceOf[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Linear]].map(com.google.api.distribution.Distribution.BucketOptions.Options.LinearBuckets)
    .orElse[com.google.api.distribution.Distribution.BucketOptions.Options](__fieldsMap.get(__fields.get(1)).asInstanceOf[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Exponential]].map(com.google.api.distribution.Distribution.BucketOptions.Options.ExponentialBuckets))
    .orElse[com.google.api.distribution.Distribution.BucketOptions.Options](__fieldsMap.get(__fields.get(2)).asInstanceOf[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Explicit]].map(com.google.api.distribution.Distribution.BucketOptions.Options.ExplicitBuckets))
    .getOrElse(com.google.api.distribution.Distribution.BucketOptions.Options.Empty)
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[com.google.api.distribution.Distribution.BucketOptions] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
        com.google.api.distribution.Distribution.BucketOptions(
          options = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).flatMap(_.as[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Linear]]).map(com.google.api.distribution.Distribution.BucketOptions.Options.LinearBuckets)
    .orElse[com.google.api.distribution.Distribution.BucketOptions.Options](__fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Exponential]]).map(com.google.api.distribution.Distribution.BucketOptions.Options.ExponentialBuckets))
    .orElse[com.google.api.distribution.Distribution.BucketOptions.Options](__fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Explicit]]).map(com.google.api.distribution.Distribution.BucketOptions.Options.ExplicitBuckets))
    .getOrElse(com.google.api.distribution.Distribution.BucketOptions.Options.Empty)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = com.google.api.distribution.Distribution.javaDescriptor.getNestedTypes.get(1)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = com.google.api.distribution.Distribution.scalaDescriptor.nestedMessages(1)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
      var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
      (__number: @_root_.scala.unchecked) match {
        case 1 => __out = com.google.api.distribution.Distribution.BucketOptions.Linear
        case 2 => __out = com.google.api.distribution.Distribution.BucketOptions.Exponential
        case 3 => __out = com.google.api.distribution.Distribution.BucketOptions.Explicit
      }
      __out
    }
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq[_root_.scalapb.GeneratedMessageCompanion[_]](
      _root_.com.google.api.distribution.Distribution.BucketOptions.Linear,
      _root_.com.google.api.distribution.Distribution.BucketOptions.Exponential,
      _root_.com.google.api.distribution.Distribution.BucketOptions.Explicit
    )
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = com.google.api.distribution.Distribution.BucketOptions(
    )
    sealed trait Options extends _root_.scalapb.GeneratedOneof {
      def isEmpty: _root_.scala.Boolean = false
      def isDefined: _root_.scala.Boolean = true
      def isLinearBuckets: _root_.scala.Boolean = false
      def isExponentialBuckets: _root_.scala.Boolean = false
      def isExplicitBuckets: _root_.scala.Boolean = false
      def linearBuckets: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Linear] = None
      def exponentialBuckets: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Exponential] = None
      def explicitBuckets: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Explicit] = None
    }
    object Options extends {
      @SerialVersionUID(0L)
      case object Empty extends com.google.api.distribution.Distribution.BucketOptions.Options {
        type ValueType = _root_.scala.Nothing
        override def isEmpty: _root_.scala.Boolean = true
        override def isDefined: _root_.scala.Boolean = false
        override def number: _root_.scala.Int = 0
        override def value: _root_.scala.Nothing = throw new java.util.NoSuchElementException("Empty.value")
      }
    
      @SerialVersionUID(0L)
      final case class LinearBuckets(value: com.google.api.distribution.Distribution.BucketOptions.Linear) extends com.google.api.distribution.Distribution.BucketOptions.Options {
        type ValueType = com.google.api.distribution.Distribution.BucketOptions.Linear
        override def isLinearBuckets: _root_.scala.Boolean = true
        override def linearBuckets: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Linear] = Some(value)
        override def number: _root_.scala.Int = 1
      }
      @SerialVersionUID(0L)
      final case class ExponentialBuckets(value: com.google.api.distribution.Distribution.BucketOptions.Exponential) extends com.google.api.distribution.Distribution.BucketOptions.Options {
        type ValueType = com.google.api.distribution.Distribution.BucketOptions.Exponential
        override def isExponentialBuckets: _root_.scala.Boolean = true
        override def exponentialBuckets: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Exponential] = Some(value)
        override def number: _root_.scala.Int = 2
      }
      @SerialVersionUID(0L)
      final case class ExplicitBuckets(value: com.google.api.distribution.Distribution.BucketOptions.Explicit) extends com.google.api.distribution.Distribution.BucketOptions.Options {
        type ValueType = com.google.api.distribution.Distribution.BucketOptions.Explicit
        override def isExplicitBuckets: _root_.scala.Boolean = true
        override def explicitBuckets: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions.Explicit] = Some(value)
        override def number: _root_.scala.Int = 3
      }
    }
    /** Specify a sequence of buckets that all have the same width (except
      * overflow and underflow).  Each bucket represents a constant absolute
      * uncertainty on the specific value in the bucket.
      *
      * Defines `num_finite_buckets + 2` (= N) buckets with these boundaries for
      * bucket `i`:
      *
      *    Upper bound (0 &lt;= i &lt; N-1):     offset + (width * i).
      *    Lower bound (1 &lt;= i &lt; N):       offset + (width * (i - 1)).
      *
      * @param numFiniteBuckets
      *   Must be greater than 0.
      * @param width
      *   Must be greater than 0.
      * @param offset
      *   Lower bound of the first bucket.
      */
    @SerialVersionUID(0L)
    final case class Linear(
        numFiniteBuckets: _root_.scala.Int = 0,
        width: _root_.scala.Double = 0.0,
        offset: _root_.scala.Double = 0.0
        ) extends scalapb.GeneratedMessage with scalapb.Message[Linear] with scalapb.lenses.Updatable[Linear] {
        @transient
        private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
        private[this] def __computeSerializedValue(): _root_.scala.Int = {
          var __size = 0
          
          {
            val __value = numFiniteBuckets
            if (__value != 0) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
            }
          };
          
          {
            val __value = width
            if (__value != 0.0) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(2, __value)
            }
          };
          
          {
            val __value = offset
            if (__value != 0.0) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(3, __value)
            }
          };
          __size
        }
        final override def serializedSize: _root_.scala.Int = {
          var read = __serializedSizeCachedValue
          if (read == 0) {
            read = __computeSerializedValue()
            __serializedSizeCachedValue = read
          }
          read
        }
        def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
          {
            val __v = numFiniteBuckets
            if (__v != 0) {
              _output__.writeInt32(1, __v)
            }
          };
          {
            val __v = width
            if (__v != 0.0) {
              _output__.writeDouble(2, __v)
            }
          };
          {
            val __v = offset
            if (__v != 0.0) {
              _output__.writeDouble(3, __v)
            }
          };
        }
        def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.google.api.distribution.Distribution.BucketOptions.Linear = {
          var __numFiniteBuckets = this.numFiniteBuckets
          var __width = this.width
          var __offset = this.offset
          var _done__ = false
          while (!_done__) {
            val _tag__ = _input__.readTag()
            _tag__ match {
              case 0 => _done__ = true
              case 8 =>
                __numFiniteBuckets = _input__.readInt32()
              case 17 =>
                __width = _input__.readDouble()
              case 25 =>
                __offset = _input__.readDouble()
              case tag => _input__.skipField(tag)
            }
          }
          com.google.api.distribution.Distribution.BucketOptions.Linear(
              numFiniteBuckets = __numFiniteBuckets,
              width = __width,
              offset = __offset
          )
        }
        def withNumFiniteBuckets(__v: _root_.scala.Int): Linear = copy(numFiniteBuckets = __v)
        def withWidth(__v: _root_.scala.Double): Linear = copy(width = __v)
        def withOffset(__v: _root_.scala.Double): Linear = copy(offset = __v)
        def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
          (__fieldNumber: @_root_.scala.unchecked) match {
            case 1 => {
              val __t = numFiniteBuckets
              if (__t != 0) __t else null
            }
            case 2 => {
              val __t = width
              if (__t != 0.0) __t else null
            }
            case 3 => {
              val __t = offset
              if (__t != 0.0) __t else null
            }
          }
        }
        def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
          _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
          (__field.number: @_root_.scala.unchecked) match {
            case 1 => _root_.scalapb.descriptors.PInt(numFiniteBuckets)
            case 2 => _root_.scalapb.descriptors.PDouble(width)
            case 3 => _root_.scalapb.descriptors.PDouble(offset)
          }
        }
        def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
        def companion = com.google.api.distribution.Distribution.BucketOptions.Linear
    }
    
    object Linear extends scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions.Linear] {
      implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions.Linear] = this
      def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, _root_.scala.Any]): com.google.api.distribution.Distribution.BucketOptions.Linear = {
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
        val __fields = javaDescriptor.getFields
        com.google.api.distribution.Distribution.BucketOptions.Linear(
          __fieldsMap.getOrElse(__fields.get(0), 0).asInstanceOf[_root_.scala.Int],
          __fieldsMap.getOrElse(__fields.get(1), 0.0).asInstanceOf[_root_.scala.Double],
          __fieldsMap.getOrElse(__fields.get(2), 0.0).asInstanceOf[_root_.scala.Double]
        )
      }
      implicit def messageReads: _root_.scalapb.descriptors.Reads[com.google.api.distribution.Distribution.BucketOptions.Linear] = _root_.scalapb.descriptors.Reads{
        case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
          _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
          com.google.api.distribution.Distribution.BucketOptions.Linear(
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Double]).getOrElse(0.0),
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Double]).getOrElse(0.0)
          )
        case _ => throw new RuntimeException("Expected PMessage")
      }
      def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = com.google.api.distribution.Distribution.BucketOptions.javaDescriptor.getNestedTypes.get(0)
      def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = com.google.api.distribution.Distribution.BucketOptions.scalaDescriptor.nestedMessages(0)
      def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
      lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
      def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
      lazy val defaultInstance = com.google.api.distribution.Distribution.BucketOptions.Linear(
      )
      implicit class LinearLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Linear]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Linear](_l) {
        def numFiniteBuckets: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.numFiniteBuckets)((c_, f_) => c_.copy(numFiniteBuckets = f_))
        def width: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.width)((c_, f_) => c_.copy(width = f_))
        def offset: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.offset)((c_, f_) => c_.copy(offset = f_))
      }
      final val NUM_FINITE_BUCKETS_FIELD_NUMBER = 1
      final val WIDTH_FIELD_NUMBER = 2
      final val OFFSET_FIELD_NUMBER = 3
      def of(
        numFiniteBuckets: _root_.scala.Int,
        width: _root_.scala.Double,
        offset: _root_.scala.Double
      ): _root_.com.google.api.distribution.Distribution.BucketOptions.Linear = _root_.com.google.api.distribution.Distribution.BucketOptions.Linear(
        numFiniteBuckets,
        width,
        offset
      )
    }
    
    /** Specify a sequence of buckets that have a width that is proportional to
      * the value of the lower bound.  Each bucket represents a constant relative
      * uncertainty on a specific value in the bucket.
      *
      * Defines `num_finite_buckets + 2` (= N) buckets with these boundaries for
      * bucket i:
      *
      *    Upper bound (0 &lt;= i &lt; N-1):     scale * (growth_factor ^ i).
      *    Lower bound (1 &lt;= i &lt; N):       scale * (growth_factor ^ (i - 1)).
      *
      * @param numFiniteBuckets
      *   Must be greater than 0.
      * @param growthFactor
      *   Must be greater than 1.
      * @param scale
      *   Must be greater than 0.
      */
    @SerialVersionUID(0L)
    final case class Exponential(
        numFiniteBuckets: _root_.scala.Int = 0,
        growthFactor: _root_.scala.Double = 0.0,
        scale: _root_.scala.Double = 0.0
        ) extends scalapb.GeneratedMessage with scalapb.Message[Exponential] with scalapb.lenses.Updatable[Exponential] {
        @transient
        private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
        private[this] def __computeSerializedValue(): _root_.scala.Int = {
          var __size = 0
          
          {
            val __value = numFiniteBuckets
            if (__value != 0) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
            }
          };
          
          {
            val __value = growthFactor
            if (__value != 0.0) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(2, __value)
            }
          };
          
          {
            val __value = scale
            if (__value != 0.0) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(3, __value)
            }
          };
          __size
        }
        final override def serializedSize: _root_.scala.Int = {
          var read = __serializedSizeCachedValue
          if (read == 0) {
            read = __computeSerializedValue()
            __serializedSizeCachedValue = read
          }
          read
        }
        def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
          {
            val __v = numFiniteBuckets
            if (__v != 0) {
              _output__.writeInt32(1, __v)
            }
          };
          {
            val __v = growthFactor
            if (__v != 0.0) {
              _output__.writeDouble(2, __v)
            }
          };
          {
            val __v = scale
            if (__v != 0.0) {
              _output__.writeDouble(3, __v)
            }
          };
        }
        def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.google.api.distribution.Distribution.BucketOptions.Exponential = {
          var __numFiniteBuckets = this.numFiniteBuckets
          var __growthFactor = this.growthFactor
          var __scale = this.scale
          var _done__ = false
          while (!_done__) {
            val _tag__ = _input__.readTag()
            _tag__ match {
              case 0 => _done__ = true
              case 8 =>
                __numFiniteBuckets = _input__.readInt32()
              case 17 =>
                __growthFactor = _input__.readDouble()
              case 25 =>
                __scale = _input__.readDouble()
              case tag => _input__.skipField(tag)
            }
          }
          com.google.api.distribution.Distribution.BucketOptions.Exponential(
              numFiniteBuckets = __numFiniteBuckets,
              growthFactor = __growthFactor,
              scale = __scale
          )
        }
        def withNumFiniteBuckets(__v: _root_.scala.Int): Exponential = copy(numFiniteBuckets = __v)
        def withGrowthFactor(__v: _root_.scala.Double): Exponential = copy(growthFactor = __v)
        def withScale(__v: _root_.scala.Double): Exponential = copy(scale = __v)
        def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
          (__fieldNumber: @_root_.scala.unchecked) match {
            case 1 => {
              val __t = numFiniteBuckets
              if (__t != 0) __t else null
            }
            case 2 => {
              val __t = growthFactor
              if (__t != 0.0) __t else null
            }
            case 3 => {
              val __t = scale
              if (__t != 0.0) __t else null
            }
          }
        }
        def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
          _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
          (__field.number: @_root_.scala.unchecked) match {
            case 1 => _root_.scalapb.descriptors.PInt(numFiniteBuckets)
            case 2 => _root_.scalapb.descriptors.PDouble(growthFactor)
            case 3 => _root_.scalapb.descriptors.PDouble(scale)
          }
        }
        def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
        def companion = com.google.api.distribution.Distribution.BucketOptions.Exponential
    }
    
    object Exponential extends scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions.Exponential] {
      implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions.Exponential] = this
      def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, _root_.scala.Any]): com.google.api.distribution.Distribution.BucketOptions.Exponential = {
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
        val __fields = javaDescriptor.getFields
        com.google.api.distribution.Distribution.BucketOptions.Exponential(
          __fieldsMap.getOrElse(__fields.get(0), 0).asInstanceOf[_root_.scala.Int],
          __fieldsMap.getOrElse(__fields.get(1), 0.0).asInstanceOf[_root_.scala.Double],
          __fieldsMap.getOrElse(__fields.get(2), 0.0).asInstanceOf[_root_.scala.Double]
        )
      }
      implicit def messageReads: _root_.scalapb.descriptors.Reads[com.google.api.distribution.Distribution.BucketOptions.Exponential] = _root_.scalapb.descriptors.Reads{
        case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
          _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
          com.google.api.distribution.Distribution.BucketOptions.Exponential(
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Double]).getOrElse(0.0),
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Double]).getOrElse(0.0)
          )
        case _ => throw new RuntimeException("Expected PMessage")
      }
      def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = com.google.api.distribution.Distribution.BucketOptions.javaDescriptor.getNestedTypes.get(1)
      def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = com.google.api.distribution.Distribution.BucketOptions.scalaDescriptor.nestedMessages(1)
      def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
      lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
      def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
      lazy val defaultInstance = com.google.api.distribution.Distribution.BucketOptions.Exponential(
      )
      implicit class ExponentialLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Exponential]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Exponential](_l) {
        def numFiniteBuckets: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.numFiniteBuckets)((c_, f_) => c_.copy(numFiniteBuckets = f_))
        def growthFactor: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.growthFactor)((c_, f_) => c_.copy(growthFactor = f_))
        def scale: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.scale)((c_, f_) => c_.copy(scale = f_))
      }
      final val NUM_FINITE_BUCKETS_FIELD_NUMBER = 1
      final val GROWTH_FACTOR_FIELD_NUMBER = 2
      final val SCALE_FIELD_NUMBER = 3
      def of(
        numFiniteBuckets: _root_.scala.Int,
        growthFactor: _root_.scala.Double,
        scale: _root_.scala.Double
      ): _root_.com.google.api.distribution.Distribution.BucketOptions.Exponential = _root_.com.google.api.distribution.Distribution.BucketOptions.Exponential(
        numFiniteBuckets,
        growthFactor,
        scale
      )
    }
    
    /** A set of buckets with arbitrary widths.
      *
      * Defines `size(bounds) + 1` (= N) buckets with these boundaries for
      * bucket i:
      *
      *    Upper bound (0 &lt;= i &lt; N-1):     bounds[i]
      *    Lower bound (1 &lt;= i &lt; N);       bounds[i - 1]
      *
      * There must be at least one element in `bounds`.  If `bounds` has only one
      * element, there are no finite buckets, and that single element is the
      * common boundary of the overflow and underflow buckets.
      *
      * @param bounds
      *   The values must be monotonically increasing.
      */
    @SerialVersionUID(0L)
    final case class Explicit(
        bounds: _root_.scala.collection.Seq[_root_.scala.Double] = _root_.scala.collection.Seq.empty
        ) extends scalapb.GeneratedMessage with scalapb.Message[Explicit] with scalapb.lenses.Updatable[Explicit] {
        private[this] def boundsSerializedSize = {
          8 * bounds.size
        }
        @transient
        private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
        private[this] def __computeSerializedValue(): _root_.scala.Int = {
          var __size = 0
          if(bounds.nonEmpty) {
            val __localsize = boundsSerializedSize
            __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__localsize) + __localsize
          }
          __size
        }
        final override def serializedSize: _root_.scala.Int = {
          var read = __serializedSizeCachedValue
          if (read == 0) {
            read = __computeSerializedValue()
            __serializedSizeCachedValue = read
          }
          read
        }
        def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
          if (bounds.nonEmpty) {
            _output__.writeTag(1, 2)
            _output__.writeUInt32NoTag(boundsSerializedSize)
            bounds.foreach(_output__.writeDoubleNoTag)
          };
        }
        def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.google.api.distribution.Distribution.BucketOptions.Explicit = {
          val __bounds = (_root_.scala.collection.immutable.Vector.newBuilder[_root_.scala.Double] ++= this.bounds)
          var _done__ = false
          while (!_done__) {
            val _tag__ = _input__.readTag()
            _tag__ match {
              case 0 => _done__ = true
              case 9 =>
                __bounds += _input__.readDouble()
              case 10 => {
                val length = _input__.readRawVarint32()
                val oldLimit = _input__.pushLimit(length)
                while (_input__.getBytesUntilLimit > 0) {
                  __bounds += _input__.readDouble
                }
                _input__.popLimit(oldLimit)
              }
              case tag => _input__.skipField(tag)
            }
          }
          com.google.api.distribution.Distribution.BucketOptions.Explicit(
              bounds = __bounds.result()
          )
        }
        def clearBounds = copy(bounds = _root_.scala.collection.Seq.empty)
        def addBounds(__vs: _root_.scala.Double*): Explicit = addAllBounds(__vs)
        def addAllBounds(__vs: TraversableOnce[_root_.scala.Double]): Explicit = copy(bounds = bounds ++ __vs)
        def withBounds(__v: _root_.scala.collection.Seq[_root_.scala.Double]): Explicit = copy(bounds = __v)
        def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
          (__fieldNumber: @_root_.scala.unchecked) match {
            case 1 => bounds
          }
        }
        def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
          _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
          (__field.number: @_root_.scala.unchecked) match {
            case 1 => _root_.scalapb.descriptors.PRepeated(bounds.map(_root_.scalapb.descriptors.PDouble)(_root_.scala.collection.breakOut))
          }
        }
        def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
        def companion = com.google.api.distribution.Distribution.BucketOptions.Explicit
    }
    
    object Explicit extends scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions.Explicit] {
      implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.google.api.distribution.Distribution.BucketOptions.Explicit] = this
      def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, _root_.scala.Any]): com.google.api.distribution.Distribution.BucketOptions.Explicit = {
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
        val __fields = javaDescriptor.getFields
        com.google.api.distribution.Distribution.BucketOptions.Explicit(
          __fieldsMap.getOrElse(__fields.get(0), Nil).asInstanceOf[_root_.scala.collection.Seq[_root_.scala.Double]]
        )
      }
      implicit def messageReads: _root_.scalapb.descriptors.Reads[com.google.api.distribution.Distribution.BucketOptions.Explicit] = _root_.scalapb.descriptors.Reads{
        case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
          _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
          com.google.api.distribution.Distribution.BucketOptions.Explicit(
            __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.collection.Seq[_root_.scala.Double]]).getOrElse(_root_.scala.collection.Seq.empty)
          )
        case _ => throw new RuntimeException("Expected PMessage")
      }
      def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = com.google.api.distribution.Distribution.BucketOptions.javaDescriptor.getNestedTypes.get(2)
      def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = com.google.api.distribution.Distribution.BucketOptions.scalaDescriptor.nestedMessages(2)
      def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
      lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
      def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
      lazy val defaultInstance = com.google.api.distribution.Distribution.BucketOptions.Explicit(
      )
      implicit class ExplicitLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Explicit]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Explicit](_l) {
        def bounds: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.Seq[_root_.scala.Double]] = field(_.bounds)((c_, f_) => c_.copy(bounds = f_))
      }
      final val BOUNDS_FIELD_NUMBER = 1
      def of(
        bounds: _root_.scala.collection.Seq[_root_.scala.Double]
      ): _root_.com.google.api.distribution.Distribution.BucketOptions.Explicit = _root_.com.google.api.distribution.Distribution.BucketOptions.Explicit(
        bounds
      )
    }
    
    implicit class BucketOptionsLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.google.api.distribution.Distribution.BucketOptions](_l) {
      def linearBuckets: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Linear] = field(_.getLinearBuckets)((c_, f_) => c_.copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.LinearBuckets(f_)))
      def exponentialBuckets: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Exponential] = field(_.getExponentialBuckets)((c_, f_) => c_.copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.ExponentialBuckets(f_)))
      def explicitBuckets: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Explicit] = field(_.getExplicitBuckets)((c_, f_) => c_.copy(options = com.google.api.distribution.Distribution.BucketOptions.Options.ExplicitBuckets(f_)))
      def options: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions.Options] = field(_.options)((c_, f_) => c_.copy(options = f_))
    }
    final val LINEAR_BUCKETS_FIELD_NUMBER = 1
    final val EXPONENTIAL_BUCKETS_FIELD_NUMBER = 2
    final val EXPLICIT_BUCKETS_FIELD_NUMBER = 3
    def of(
      options: com.google.api.distribution.Distribution.BucketOptions.Options
    ): _root_.com.google.api.distribution.Distribution.BucketOptions = _root_.com.google.api.distribution.Distribution.BucketOptions(
      options
    )
  }
  
  implicit class DistributionLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.google.api.distribution.Distribution](_l) {
    def count: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.count)((c_, f_) => c_.copy(count = f_))
    def mean: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.mean)((c_, f_) => c_.copy(mean = f_))
    def sumOfSquaredDeviation: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.sumOfSquaredDeviation)((c_, f_) => c_.copy(sumOfSquaredDeviation = f_))
    def range: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.Range] = field(_.getRange)((c_, f_) => c_.copy(range = Option(f_)))
    def optionalRange: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[com.google.api.distribution.Distribution.Range]] = field(_.range)((c_, f_) => c_.copy(range = f_))
    def bucketOptions: _root_.scalapb.lenses.Lens[UpperPB, com.google.api.distribution.Distribution.BucketOptions] = field(_.getBucketOptions)((c_, f_) => c_.copy(bucketOptions = Option(f_)))
    def optionalBucketOptions: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions]] = field(_.bucketOptions)((c_, f_) => c_.copy(bucketOptions = f_))
    def bucketCounts: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.Seq[_root_.scala.Long]] = field(_.bucketCounts)((c_, f_) => c_.copy(bucketCounts = f_))
  }
  final val COUNT_FIELD_NUMBER = 1
  final val MEAN_FIELD_NUMBER = 2
  final val SUM_OF_SQUARED_DEVIATION_FIELD_NUMBER = 3
  final val RANGE_FIELD_NUMBER = 4
  final val BUCKET_OPTIONS_FIELD_NUMBER = 6
  final val BUCKET_COUNTS_FIELD_NUMBER = 7
  def of(
    count: _root_.scala.Long,
    mean: _root_.scala.Double,
    sumOfSquaredDeviation: _root_.scala.Double,
    range: _root_.scala.Option[com.google.api.distribution.Distribution.Range],
    bucketOptions: _root_.scala.Option[com.google.api.distribution.Distribution.BucketOptions],
    bucketCounts: _root_.scala.collection.Seq[_root_.scala.Long]
  ): _root_.com.google.api.distribution.Distribution = _root_.com.google.api.distribution.Distribution(
    count,
    mean,
    sumOfSquaredDeviation,
    range,
    bucketOptions,
    bucketCounts
  )
}
